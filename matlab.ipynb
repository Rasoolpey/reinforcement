{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "import socket, struct\n",
    "import control as ctrl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy import integrate\n",
    "import torch.nn.functional as F\n",
    "import threading\n",
    "import concurrent.futures\n",
    "# import subprocess\n",
    "# import os\n",
    "# import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## matlab api connection\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.cd(r'C:\\Users\\pvm8318\\Documents\\NeoVim\\Reinforcement')\n",
    "eng.addpath(r'C:\\Users\\pvm8318\\Documents\\NeoVim\\Reinforcement')\n",
    "def SimRun():\n",
    "    eng.sim('Buck_Converter.slx')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TCP Connection\n",
    "MESSAGE_SIZE = 24\n",
    "DELIMITER = b'\\n'\n",
    "TCP_IP = '156.62.139.28'\n",
    "TCP_PORT = 50000\n",
    "BUFFER_SIZE = MESSAGE_SIZE if MESSAGE_SIZE else 32  # Minimum for two doubles\n",
    "\n",
    "\n",
    "def send_data(conn, val):\n",
    "    \"\"\"Sends two double-precision numbers.\"\"\"\n",
    "    # Fixed Size\n",
    "    msg = struct.pack('>d', val)\n",
    "    conn.send(msg)\n",
    "\n",
    "def receive_data(conn):\n",
    "    \"\"\"Receives three double-precision numbers.\"\"\"\n",
    "    if MESSAGE_SIZE:\n",
    "        data = conn.recv(MESSAGE_SIZE)\n",
    "        val1, val2, Time = struct.unpack('>ddd', data)\n",
    "    else:\n",
    "        # Delimiter\n",
    "        val1 = None\n",
    "        val2 = None\n",
    "        Time = None\n",
    "        while True:\n",
    "            data = conn.recv(BUFFER_SIZE)\n",
    "            if DELIMITER in data:\n",
    "                val1_bytes, remaining = data.split(DELIMITER, 1)\n",
    "                val1 = struct.unpack('>d', val1_bytes)[0]\n",
    "                if DELIMITER in remaining:\n",
    "                    val2_bytes, time_bytes = remaining.split(DELIMITER, 1)\n",
    "                    val2 = struct.unpack('>d', val2_bytes)[0]\n",
    "                    Time = struct.unpack('>d', time_bytes)[0]\n",
    "                    break\n",
    "    return val1, val2, Time\n",
    "\n",
    "# Close the existing socket connection if it is open\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Buck converter parameters \n",
    "Vref = 5\n",
    "u = 0\n",
    "R = 1.0  # Resistance\n",
    "L = 0.1  # Inductance\n",
    "C = 1e-3  # Capacitance\n",
    "Vin = 12.0  # Input voltage\n",
    "Vref = 5.0  # Reference output voltage.0\n",
    "# State-space representation of the buck converter\n",
    "A = np.array([[0, 1 / C], [-1 / L, -R / L]])\n",
    "B = np.array([[0], [1 / L]])\n",
    "#steady state calculation\n",
    "duty_cycle =Vref/Vin\n",
    "Iout = Vref/R\n",
    "ILref = Iout/duty_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RL Configuration\n",
    "input_size = 2\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "F = nn.functional\n",
    "class Agent(nn.Module):\n",
    "        def __init__(self):\n",
    "                super(Agent, self).__init__()\n",
    "                self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "                self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "                x = F.relu(self.layer1(x))\n",
    "                x = self.layer2(x)\n",
    "                return x\n",
    "\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "# reward calculation\n",
    "def reward(x, u):\n",
    "        V = x[0]\n",
    "        IL = x[1]\n",
    "        Q = 10*np.eye(2)  # State penalty matrix\n",
    "        R = 1 \n",
    "        reward = -np.linalg.norm(x - np.array([Vref, ILref]))**2 \n",
    "        # reward = -np.linalg.norm(x - np.array([Vref, ILref]))**2 - u**2 * R\n",
    "        return reward\n",
    "\n",
    "# RL Agent \n",
    "class RandomPolicy(nn.Module):\n",
    "        def forward(self, state):\n",
    "                # Random policy: sample a random action\n",
    "                return torch.rand(1)\n",
    "        \n",
    "# Control law\n",
    "def control_law(x):\n",
    "        with torch.no_grad():\n",
    "                action = agent(torch.tensor(x, dtype=torch.float32))\n",
    "        return action.item()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL Configuration\n",
    "# class Actor(nn.Module):\n",
    "#     def __init__(self, state_dim, action_dim, max_action):\n",
    "#         super(Actor, self).__init__()\n",
    "\n",
    "#         self.l1 = nn.Linear(state_dim, 400)\n",
    "#         self.l2 = nn.Linear(400, 300)\n",
    "#         self.l3 = nn.Linear(300, action_dim)\n",
    "\n",
    "#         self.max_action = max_action\n",
    "\n",
    "#     def forward(self, state):\n",
    "#         a = F.relu(self.l1(state))\n",
    "#         a = F.relu(self.l2(a))\n",
    "#         return self.max_action * torch.sigmoid(self.l3(a))\n",
    "\n",
    "\n",
    "# class Critic(nn.Module):\n",
    "#     def __init__(self, state_dim, action_dim):\n",
    "#         super(Critic, self).__init__()\n",
    "\n",
    "#         self.l1 = nn.Linear(state_dim + action_dim, 400)\n",
    "#         self.l2 = nn.Linear(400, 300)\n",
    "#         self.l3 = nn.Linear(300, 1)\n",
    "\n",
    "#     def forward(self, state, action):\n",
    "#         state_action = torch.cat([state, action], 1)\n",
    "\n",
    "#         q = F.relu(self.l1(state_action))\n",
    "#         q = F.relu(self.l2(q))\n",
    "\n",
    "#         return self.l3(q)\n",
    "\n",
    "\n",
    "# class DDPG(object):\n",
    "#     def __init__(self, state_dim, action_dim, max_action):\n",
    "#         self.actor = Actor(state_dim, action_dim, max_action)\n",
    "#         self.actor_target = Actor(state_dim, action_dim, max_action)\n",
    "#         self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "#         self.actor_optimizer = torch.optim.Adam(self.actor.parameters())\n",
    "\n",
    "#         self.critic = Critic(state_dim, action_dim)\n",
    "#         self.critic_target = Critic(state_dim, action_dim)\n",
    "#         self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "#         self.critic_optimizer = torch.optim.Adam(self.critic.parameters())\n",
    "\n",
    "#         self.max_action = max_action\n",
    "\n",
    "#     def select_action(self, state):\n",
    "#         state = torch.FloatTensor(state.reshape(1, -1))\n",
    "#         return self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "#     def update(self, state, action, reward, next_state, done):\n",
    "#         # Update the agent's parameters based on the transition\n",
    "#         pass\n",
    "#         action = agent.select_action(state)\n",
    "#         next_state = [val1, val2]\n",
    "#         # Perform action in the environment\n",
    "#         # next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "#         # Update agent\n",
    "#         # Note: You would typically store these transitions in a replay buffer and sample from it\n",
    "#         agent.update(state, action, reward, next_state, done)\n",
    "\n",
    "#         # Update state\n",
    "#         state = next_state\n",
    "\n",
    "#         # Break if done\n",
    "#         if done:\n",
    "#             t=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Close the existing socket connection if it is open\n",
    "# if 's' in locals() and s.fileno() != -1:\n",
    "#     s.close()\n",
    "\n",
    "# Create a new socket and bind to the address and port\n",
    "def websocket ():\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.bind((TCP_IP, TCP_PORT))\n",
    "    print('Waiting for Simulink to start')\n",
    "    s.listen(1)\n",
    "    conn, addr = s.accept()\n",
    "    return conn\n",
    "\n",
    "\n",
    "# s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "# s.bind((TCP_IP, TCP_PORT))\n",
    "# print('Waiting for Simulink to start')\n",
    "# s.listen(1)\n",
    "# conn, addr = s.accept()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewardcal(x, u):\n",
    "    V = x[0]\n",
    "    IL = x[1]\n",
    "    Q = 10*np.eye(2)  # State penalty matrix\n",
    "    R = 1 \n",
    "    reward = -np.linalg.norm(x - np.array([Vref, ILref]))**2 \n",
    "    # reward = -np.linalg.norm(x - np.array([Vref, ILref]))**2 - u**2 * R\n",
    "    return reward\n",
    "\n",
    "\n",
    "def isdone(x, t):\n",
    "    # Define the desirable band\n",
    "    desirable_band = [4.8, 5.2]\n",
    "\n",
    "    # Initialize the start time and t0\n",
    "    t0 = None\n",
    "\n",
    "    V = x[0]\n",
    "    IL = x[1]\n",
    "    \n",
    "    # Check if the state is within the desirable band\n",
    "    if V >= desirable_band[0] and V <= desirable_band[1]:\n",
    "        # Check if t0 is None (first time in the band)\n",
    "        if t0 is None:\n",
    "            t0 = t\n",
    "        # Check if the state has been within the desirable band for 0.5 seconds\n",
    "        elif t - t0 >= 0.5:\n",
    "            return True\n",
    "    else:\n",
    "        # Reset t0 if V gets out of the band\n",
    "        t0 = None\n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Simulink to start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-65 (SimRun):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pvm8318\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\pvm8318\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\pvm8318\\AppData\\Local\\Temp\\ipykernel_32364\\3591277765.py\", line 6, in SimRun\n",
      "  File \"c:\\Users\\pvm8318\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matlab\\engine\\matlabengine.py\", line 71, in __call__\n",
      "    _stderr, feval=True).result()\n",
      "                         ^^^^^^^^\n",
      "  File \"c:\\Users\\pvm8318\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matlab\\engine\\futureresult.py\", line 67, in result\n",
      "    return self.__future.result(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pvm8318\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matlab\\engine\\fevalfuture.py\", line 82, in result\n",
      "    self._result = pythonengine.getFEvalResult(self._future,self._nargout, None, out=self._out, err=self._err)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "matlab.engine.MatlabExecutionError: MATLAB System block 'Buck_Converter/TCP//IP Receive' error occurred when invoking 'stepImpl' method of 'instrument.system.TCPIPReceive'. The error was thrown from '\n",
      " <a href=\"matlab:opentoline('C:\\Program Files\\MATLAB\\R2023b\\toolbox\\instrument\\instrumentblks\\+instrument\\+system\\TCPIPReceive.m',388, 0)\">'C:\\Program Files\\MATLAB\\R2023b\\toolbox\\instrument\\instrumentblks\\+instrument\\+system\\TCPIPReceive.m'</a> at line 388'.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "\n",
    "# sys.setrecursionlimit(10000)\n",
    "# state_dim = 2\n",
    "# action_dim = 1\n",
    "# max_action = 1\n",
    "# agent = DDPG(state_dim, action_dim, max_action)\n",
    "\n",
    "# # Number of episodes\n",
    "# num_episodes = 50\n",
    "\n",
    "# # Loop over episodes\n",
    "# for i_episode in range(num_episodes):\n",
    "\n",
    "#     # Reset the environment and state\n",
    "#     # state = env.reset()\n",
    "#     t1 = threading.Thread(target=SimRun)\n",
    "#     t1.start()\n",
    "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#         future2 = executor.submit(websocket)\n",
    "#         conn = future2.result()\n",
    "#     time = 0\n",
    "#     state = np.array([0, 0])\n",
    "#     # Loop over steps within this episode\n",
    "#     while time<30:\n",
    "#         send_data(conn, u)\n",
    "\n",
    "#         val1, val2,time = receive_data(conn)\n",
    "#         reward = rewardcal([val1, val2], u)\n",
    "#         done = isdone([val1, val2], time)\n",
    "#         # Select action\n",
    "#         action = agent.select_action(state)\n",
    "#         next_state = [val1, val2]\n",
    "#         # Perform action in the environment\n",
    "#         # next_state, reward, done, _ = env.step(action)\n",
    "#         sys.maximum_recursion_depth = 10000\n",
    "#         # Update agent\n",
    "#         # Note: You would typically store these transitions in a replay buffer and sample from it\n",
    "#         agent.update(state, action, reward, next_state, done)\n",
    "\n",
    "#         # Update state\n",
    "#         state = next_state\n",
    "\n",
    "#         # Break if done\n",
    "#         if done:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Simulink to start\n"
     ]
    }
   ],
   "source": [
    "# num_episodes = 10\n",
    "\n",
    "# # Run the episodes\n",
    "for episode in range(num_episodes):\n",
    "    t1 = threading.Thread(target=SimRun)\n",
    "    t1.start()\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future2 = executor.submit(websocket)\n",
    "        conn = future2.result()\n",
    "    time = 0\n",
    "    while time<2:\n",
    "\n",
    "        send_data(conn, u)\n",
    "\n",
    "        val1, val2,time = receive_data(conn)\n",
    "\n",
    "\n",
    "        x= np.array([val1,val2])\n",
    "        u = control_law(x)\n",
    "\n",
    "\n",
    "        print('Duty cycle is:', u)\n",
    "        print('time is:', time)\n",
    "    # Close the connection\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
