{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:23:21.985047: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 16:23:22.469356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:23:23.972773: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 16:23:23.976654: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matlab.engine\n",
    "import socket, struct\n",
    "import threading\n",
    "import concurrent.futures\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## matlab api connection\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.cd(r'/home/pvm8318/Documents/Reinforcement/2023b')\n",
    "eng.addpath(r'/home/pvm8318/Documents/Reinforcement/2023b')\n",
    "def SimRun():\n",
    "    eng.sim('Buck_Converter.slx')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3264257124.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:55:38.660879: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 16:55:39.144937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.16.1\n",
      "WARNING:tensorflow:From /tmp/ipykernel_588254/1804789641.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Is GPU available:  False\n",
      "CUDA enabled:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 16:55:39.466802: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-24 16:55:39.470605: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "print(\"Is GPU available: \", tf.test.is_gpu_available())\n",
    "print(\"CUDA enabled: \", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TCP Connection\n",
    "MESSAGE_SIZE = 24\n",
    "DELIMITER = b'\\n'\n",
    "TCP_IP = '127.0.0.1'\n",
    "TCP_PORT = 50000\n",
    "BUFFER_SIZE = MESSAGE_SIZE if MESSAGE_SIZE else 32  # Minimum for two doubles\n",
    "\n",
    "\n",
    "def send_data(conn, val):\n",
    "    \"\"\"Sends two double-precision numbers.\"\"\"\n",
    "    # Fixed Size\n",
    "    msg = struct.pack('>d', val)\n",
    "    conn.send(msg)\n",
    "\n",
    "def receive_data(conn):\n",
    "    \"\"\"Receives three double-precision numbers.\"\"\"\n",
    "    if MESSAGE_SIZE:\n",
    "        data = conn.recv(MESSAGE_SIZE)\n",
    "        val1, val2, Time = struct.unpack('>ddd', data)\n",
    "    else:\n",
    "        # Delimiter\n",
    "        val1 = None\n",
    "        val2 = None\n",
    "        Time = None\n",
    "        while True:\n",
    "            data = conn.recv(BUFFER_SIZE)\n",
    "            if DELIMITER in data:\n",
    "                val1_bytes, remaining = data.split(DELIMITER, 1)\n",
    "                val1 = struct.unpack('>d', val1_bytes)[0]\n",
    "                if DELIMITER in remaining:\n",
    "                    val2_bytes, time_bytes = remaining.split(DELIMITER, 1)\n",
    "                    val2 = struct.unpack('>d', val2_bytes)[0]\n",
    "                    Time = struct.unpack('>d', time_bytes)[0]\n",
    "                    break\n",
    "    return val1, val2, Time\n",
    "\n",
    "# Close the existing socket connection if it is open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Buck converter parameters \n",
    "Vref = 5\n",
    "u = 0\n",
    "R = 1.0  # Resistance\n",
    "L = 0.1  # Inductance\n",
    "C = 1e-3  # Capacitance\n",
    "Vin = 12.0  # Input voltage\n",
    "Vref = 5.0  # Reference output voltage.0\n",
    "# State-space representation of the buck converter\n",
    "A = np.array([[0, 1 / C], [-1 / L, -R / L]])\n",
    "B = np.array([[0], [1 / L]])\n",
    "#steady state calculation\n",
    "duty_cycle =Vref/Vin\n",
    "Iout = Vref/R\n",
    "ILref = Iout/duty_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def websocket ():\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.bind((TCP_IP, TCP_PORT))\n",
    "    print('Waiting for Simulink to start')\n",
    "    s.listen(1)\n",
    "    conn, addr = s.accept()\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewardcal(x, u):\n",
    "    V = x[0]\n",
    "    IL = x[1]\n",
    "    Q = 10*np.eye(2)  # State penalty matrix\n",
    "    R = 1 \n",
    "    reward = -np.linalg.norm(x - np.array([Vref, ILref]))**2 \n",
    "    # reward = -np.linalg.norm(x - np.array([Vref, ILref]))**2 - u**2 * R\n",
    "    return reward\n",
    "\n",
    "\n",
    "def isdone(x, t):\n",
    "    # Define the desirable band\n",
    "    desirable_band = [4.8, 5.2]\n",
    "\n",
    "    # Initialize the start time and t0\n",
    "    t0 = None\n",
    "\n",
    "    V = x[0]\n",
    "    IL = x[1]\n",
    "    \n",
    "    # Check if the state is within the desirable band\n",
    "    if V >= desirable_band[0] and V <= desirable_band[1]:\n",
    "        # Check if t0 is None (first time in the band)\n",
    "        if t0 is None:\n",
    "            t0 = t\n",
    "        # Check if the state has been within the desirable band for 0.5 seconds\n",
    "        elif t - t0 >= 0.5:\n",
    "            return True\n",
    "    else:\n",
    "        # Reset t0 if V gets out of the band\n",
    "        t0 = None\n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Simulink to start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m     actor_loss_value \u001b[38;5;241m=\u001b[39m actor_loss(log_prob, advantage)\n\u001b[1;32m     81\u001b[0m actor_gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(actor_loss_value, shared_net\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m---> 82\u001b[0m \u001b[43mactor_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactor_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Update the Critic network\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:281\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    280\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:334\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    327\u001b[0m grads, trainable_variables \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overwrite_variables_directly_with_gradients(\n\u001b[1;32m    329\u001b[0m         grads, trainable_variables\n\u001b[1;32m    330\u001b[0m     )\n\u001b[1;32m    331\u001b[0m )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Filter empty gradients.\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_empty_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(grads)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:661\u001b[0m, in \u001b[0;36mBaseOptimizer._filter_empty_gradients\u001b[0;34m(self, grads, vars)\u001b[0m\n\u001b[1;32m    658\u001b[0m         missing_grad_vars\u001b[38;5;241m.\u001b[39mappend(v\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered_grads:\n\u001b[0;32m--> 661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_grad_vars:\n\u001b[1;32m    663\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradients do not exist for variables \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(missing_grad_vars))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when minimizing the loss.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m If using `model.compile()`, did you forget to provide a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`loss` argument?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    668\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MATLAB System block 'Buck_Converter/TCP//IP Receive' error occurred when invoking 'stepImpl' method of 'instrument.system.TCPIPReceive'. The error was thrown from '\n",
      " <a href=\"matlab:opentoline('/usr/local/MATLAB/R2023b/toolbox/instrument/instrumentblks/+instrument/+system/TCPIPReceive.m',388, 0)\">'/usr/local/MATLAB/R2023b/toolbox/instrument/instrumentblks/+instrument/+system/TCPIPReceive.m'</a> at line 388'.\n",
      "Caused by:\n",
      "    Error receiving data from the remote server.\n",
      "    Additional Information: Operation timed out before requested data was received.\n",
      "\n",
      "Exception in thread Thread-24 (SimRun):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/pvm8318/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_444535/1695220910.py\", line 6, in SimRun\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/matlab/engine/matlabengine.py\", line 71, in __call__\n",
      "    _stderr, feval=True).result()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/matlab/engine/futureresult.py\", line 67, in result\n",
      "    return self.__future.result(timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/matlab/engine/fevalfuture.py\", line 82, in result\n",
      "    self._result = pythonengine.getFEvalResult(self._future,self._nargout, None, out=self._out, err=self._err)\n",
      "matlab.engine.MatlabExecutionError: MATLAB System block 'Buck_Converter/TCP//IP Receive' error occurred when invoking 'stepImpl' method of 'instrument.system.TCPIPReceive'. The error was thrown from '\n",
      " <a href=\"matlab:opentoline('/usr/local/MATLAB/R2023b/toolbox/instrument/instrumentblks/+instrument/+system/TCPIPReceive.m',388, 0)\">'/usr/local/MATLAB/R2023b/toolbox/instrument/instrumentblks/+instrument/+system/TCPIPReceive.m'</a> at line 388'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# close the connection if it is open\n",
    "try:\n",
    "    conn.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Define the shared network architecture\n",
    "def shared_network(state_dim, action_dim):\n",
    "    inputs = tf.keras.layers.Input(shape=(state_dim,))\n",
    "    hidden1 = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "    hidden2 = tf.keras.layers.Dense(64, activation='relu')(hidden1)\n",
    "    actor_output = tf.keras.layers.Dense(action_dim, activation='sigmoid')(hidden2)  # Output range: [0, 1]\n",
    "    critic_output = tf.keras.layers.Dense(1)(hidden2)  # Linear activation for value estimation\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[actor_output, critic_output])\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "state_dim = 2  # Number of state features (Vc and IL)\n",
    "action_dim = 1  # Single action (duty cycle)\n",
    "Vinit = 0\n",
    "Iinit = 0\n",
    "max_steps = 30 / 1e-5\n",
    "\n",
    "# Create the shared network\n",
    "shared_net = shared_network(state_dim, action_dim)\n",
    "\n",
    "# Define optimizer and loss functions\n",
    "actor_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "critic_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Actor loss function (policy gradient with advantage)\n",
    "def actor_loss(log_probs, advantages):\n",
    "    return -tf.reduce_mean(log_probs * advantages)\n",
    "\n",
    "# Critic loss function (mean squared error)\n",
    "def critic_loss(targets, predicted_values):\n",
    "    return tf.reduce_mean(tf.square(targets - predicted_values))\n",
    "\n",
    "# Compute advantages for a specific state-action pair\n",
    "def compute_advantage(q_value, v_value):\n",
    "    return q_value - v_value\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 1000  # Number of episodes\n",
    "runtime = 30  # Maximum steps per episode\n",
    "gamma = 0.9  # Discount factor\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    t1 = threading.Thread(target=SimRun)\n",
    "    t1.start()\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future2 = executor.submit(websocket)\n",
    "        conn = future2.result()\n",
    "\n",
    "    # Reset the environment and get the initial state\n",
    "    state = np.array([Vinit, Iinit])  # Replace with actual initial state\n",
    "    total_reward = 0\n",
    "    time = 0\n",
    "    u = 0\n",
    "\n",
    "    while time < runtime:\n",
    "        action_probabilities = shared_net(np.expand_dims(state, axis=0))[0][0]\n",
    "        action_probs_softmax = tf.nn.softmax(action_probabilities).numpy()\n",
    "        u = np.random.choice(np.arange(action_dim), p=action_probs_softmax)\n",
    "\n",
    "        send_data(conn, u)\n",
    "        val1, val2, time = receive_data(conn)\n",
    "        next_state = np.array([val1, val2])\n",
    "        reward = rewardcal(next_state, u)\n",
    "        done = isdone(next_state, time)\n",
    "\n",
    "        # Compute the advantage for this state-action pair\n",
    "        q_value = shared_net(np.expand_dims(state, axis=0))[1][0]\n",
    "        v_value = shared_net(np.expand_dims(state, axis=0))[1][0]\n",
    "        advantage = compute_advantage(q_value, v_value)\n",
    "\n",
    "        # Update the Actor network\n",
    "        with tf.GradientTape() as tape:\n",
    "            log_prob = tf.math.log(action_probabilities[u])\n",
    "            actor_loss_value = actor_loss(log_prob, advantage)\n",
    "        actor_gradients = tape.gradient(actor_loss_value, shared_net.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(zip(actor_gradients, shared_net.trainable_variables))\n",
    "\n",
    "        # Update the Critic network\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_value = total_reward\n",
    "            critic_loss_value = critic_loss(target_value, shared_net(np.expand_dims(state, axis=0))[1][0])\n",
    "        critic_gradients = tape.gradient(critic_loss_value, shared_net.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(zip(critic_gradients, shared_net.trainable_variables))\n",
    "\n",
    "        # Update state for the next step\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        # Print the total reward for the episode\n",
    "        print(\"reward is:\", reward)\n",
    "        print('Duty cycle is:', u)\n",
    "        print('time is:', time)\n",
    "\n",
    "        if done:\n",
    "            break  # End the episode if termination condition is met\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
